\section{Related Work}

We discuss related work in managing resources to meet performance
goals and reduce energy.  

\subsection{Machine Learning}
We break learning for resource management into 3 categories: offline,
online, and hybrid approaches.

\noindent \textbf{Offline Learning} These approaches build models
before deployment and then use those fixed models to allocate
resources
\cite{Yi2003,LeeBrooks2006,CPR,ChenJohn2011,petabricksStatic}.  The
model-building phase is expensive, requiring both a large number of
samples and substantial computation.  Applying the model online,
however, is low overhead.  The main drawback is that the models are
not updated as the system runs: a problem for adapting workloads.
\PUNT{A good example of an offline approach applies learning to render
  web pages on mobile systems with low energy \cite{reddiHPCA2013}. It
  builds an offline model mapping web page features into performance
  for different core types.  When a new page is downloaded, the system
  estimates the resources needed to render the web page and uses the
  lowest energy configuration that meets user satisfaction.  This
  approach handles the complexity of allocating resources to webpage
  rendering, but cannot address dynamics; \eg{} when other apps run
  concurrently with the web browser.}  Carat is a good example of an
offline learner that aggregates data across multiple devices to
generate a report for human users about how to configure their device
to increase battery life \cite{carat}.  While both Carat and \SYSTEM{}
learn across devices, they have very different goals.  Carat returns
very high-level information to human users; \eg{} update a driver to
extend battery life.  \SYSTEM{} automatically builds and applies
low-level models to save energy.

\noindent \textbf{Online Learning} Online techniques observe the
current application to tune system resource usage for that application
\cite{Li2006,Flicker,ParallelismDial,Ponamarev,petabricksDynamic,LeeBrooks}.
For example, Flicker is a configurable architecture and optimization
framework that uses online models to maximize performance under a
power limitation \cite{Flicker}.  Another example, ParallelismDial,
uses online adaptation to tailor parallelism to application workload
\cite{ParallelismDial}.



\noindent \textbf{Hybrid Approaches} Some approaches combine offline
predictive models with online adaptation
\cite{Zhang2012,packandcap,Winter2010,dubach2010,Koala,Cinder,
  wu2012inferred}.  For example, Dubach et al.  use hybrid models to
optimize the microarchitecture of a single core \cite{dubach2010}.
Such predictive models have also been employed at the operating system
level to manage system energy consumption
\cite{Koala,Cinder,wu2012inferred}.  Other approaches combine offline
modeling with online updates \cite{JouleGuard,Bitirgen2008,Ipek}.  For
example, Bitirgen et al use an artificial neural network to allocate
resources to multiple applications in a multicore \cite{Bitirgen2008}.
The neural network is trained offline and then adapted online using
measured feedback.  This approach maximizes performance but does not
consider power or energy minimization.

\subsection{Control}
Almost all control solutions can be thought of as a combination of
offline model building with online adaptation.  The model building
involves substantial empirical measurement that is used to synthesize
a control system
\cite{Wu2004,TCST,Chen2011,PTRADE,POET,ControlWare,Agilos,Rajkumar,Sojka,Raghavendra2008}.
The combination of offline learning and control works well over a
narrow range of applications, as the offline models capture the
general behavior of a class of application and require negligible
online overhead.  This focused approach is extremely effective for
multimedia applications \cite{grace2,flinn99,flinn2004,xtune,TCST} and
web-servers \cite{Horvarth,LuEtAl-2006a,SunDaiPan-2008a} because the
workloads can be characterized ahead of time so that the models
produce sound control.

Indeed, the need for good models is the central tension in developing
control for computing systems.  It is always possible to build a
controller for a specific application and system by extensively
modeling that pair.  More general controllers, which work with a range
of applications, have addressed the need for models in various ways.
Some provide libraries that encapsulate control functionality and
require user-specified models
\cite{ControlWare,Sojka,Rajkumar,POET,SWiFT}.  Others automatically
synthesize both a model and a controller for either hardware
\cite{josep-isca2016} or software \cite{ICSE2014,FSE2015}.  JouleGuard
combines learning for energy efficiency with control for managing
application parameters \cite{JouleGuard}.  In JouleGuard, a learner
adapts the controller's coefficients to model uncertainty, but
JouleGuard's learner does not produce a new model for the controller.
Because JouleGuard's learner runs on the same device as the controlled
application, it must be computationally efficient and thus it cannot
identify correlations across applications or even different resource
configurations.  \SYSTEM{} is unique in that a separate learner
generates an application-specific model automatically.  By offloading
the learning task, \SYSTEM{} (1) combines data from many applications
and systems and (2) applies computationally expensive, but highly
accurate learning techniques.


