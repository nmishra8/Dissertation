\section{Background and Motivation}
\label{sec:example}
Many learning approaches estimate an application's most energy
efficient resource allocation.  These include \emph{offline}
techniques that train models and then apply those models to new
applications
\cite{Yi2003,LeeBrooks2006,CPR,reddiHPCA2013,PUPiL,quasar}.
\emph{Online} techniques construct models dynamically as an
application runs
\cite{Li2006,Flicker,ParallelismDial,Ponamarev,LeeBrooks}.
\emph{Hybrid} techniques combine offline modeling with online model
updates \cite{packandcap,Winter2010,dubach2010,Koala,Cinder,
  wu2012inferred,LEO}.

Control theory provides techniques for maintaining desired behavior in
dynamic systems \cite{Hellerstein2004a}. \emph{Adaptive controllers}
or \emph{self-tuning regulators} adjust their internal models in
response to dynamic changes \cite{HandbookControl}. They are
especially useful in webservers with fluctuating request rates
\cite{Horvarth,LuEtAl-2006a,SunDaiPan-2008a} and multimedia
applications with dynamically varying inputs
\cite{TCST,Agilos,grace2}.  Prior work has generalized adaptive
control design by exposing key model parameters to users who customize
control to their needs \cite{ControlWare,POET}.  User customization
provides greater flexibility, but the controller will not converge to
the desired performance if the custom models do not accurately capture
the relationship between resources and performance.  This practice
means users must not only be experts in their application domain, but
must also have sufficient control knowledge to specify robust models.

This section illustrates how learning handles complexity, how control
handles dynamics, and then describes a key difficulty that must be
overcome to combine learning and control.

\subsection{\emph{Learning} Complexity}
\begin{figure}
\centering
  \subfloat[]
  {
    \includegraphics[width=.25\textwidth]{figures/STREAM-contour.pdf}
    \label{fig:STREAM_contour}
  }
  \subfloat[]
  {
    \input{img/STREAM-example-resized.tex}
    \label{fig:STREAM_timeline}
  }
  \caption{(a) \texttt{STREAM} performance as a function of
    configuration.  (b) Managing \texttt{STREAM}'s performance:
    \emph{Learning} handles the complex configuration space, but
    \emph{control} oscillates.}
  \label{fig:learning-models1}
\end{figure}

We demonstrate how well learning handles complex resource interaction
for \texttt{STREAM} on an ARM big.LITTLE processor with four big,
high-performance cores and four LITTLE, energy efficient cores.  The
big cores support 19 clock speeds, while the LITTLE cores support 14.


\figref{fig:STREAM_contour} shows \texttt{STREAM}'s performance for
different resource configurations.  This memory-bound application has
complicated behavior: the LITTLE cores' memory hierarchy cannot
deliver the required performance.  The big cores' more powerful memory
system delivers much greater performance, but the peak occurs with 3
big cores.  Furthermore, at low clockspeeds, these 3 big cores cannot
saturate the memory bandwidth, while at high clockspeeds the
performance drops as the processor overheats, triggering thermal
management.  For \texttt{STREAM}, the peak speed occurs with 3 big
cores at 1.2 GHz, and it is not efficient to spend any time on the
LITTLE cores.  \texttt{STREAM}, however, does not have distinct
phases, so once a resource allocator finds the most energy efficient
configuration, it simply needs to maintain it.


\figref{fig:STREAM_timeline} shows 20 iterations of both learning
\cite{LEO} and adaptive control \cite{POET} allocating resources to
\texttt{STREAM}.  The x-axis shows iteration and the y-axis shows
performance normalized to the requirement.  The \emph{learning}
approach estimates \texttt{STREAM}'s performance and power for all
configurations and uses the lowest energy configuration that delivers
the required performance.  The \emph{adaptive controller} begins with
a generic model of power/performance tradeoffs.  As the controller
runs, it measures performance and adjusts both the allocated resources
and its own parameters using online measurements.  The adaptive
controller dynamically adjusts to non-linearities with a series of
linear approximations; however, it is sensitive to model inaccuracies,
which cause the oscillations that lead to performance violations.
This behavior occurs because the controller's adaptive mechanisms
cannot handle the STREAM's complexity, a known limitation of adaptive
control systems \cite{ControlWare,POET,ICSE2014}.  Hence, the
\emph{learner}'s ability to model complex behavior is crucial.

\subsection{\emph{Controlling} Dynamics}

\begin{figure}
\centering
  \subfloat[]
  {
    \includegraphics[width=.25\textwidth]{figures/BODYTRACK-contour.png}
    \label{fig:BODYTRACK_contour}
  }
  \subfloat[]
  {
    \input{img/BODYTRACK-example-resized.tex}
    \label{fig:BODYTRACK_timeline}    
  }
  \caption{(a) \texttt{bodytrack} performance as a function of
    configuration. (b) Managing \texttt{bodytrack}'s performance with
    another application: \emph{control} detects the change (at the
    vertical dashed line) and adjusts, but \emph{learning} cannot. }
  \label{fig:control}
\end{figure}


We now consider a dynamic environment.  We begin with
\texttt{bodytrack} running alone on the system.  Halfway through its
execution, we launch a second application---\texttt{STREAM}---on a
single big core, dynamically changing available resources.
\figref{fig:BODYTRACK_contour} shows \texttt{bodytrack}'s behavior.
It achieves the best performance on 4 big cores at the highest
clockspeed; the 4 LITTLE are more energy-efficient but slower.  For
\texttt{bodytrack}, the challenge is determining how to split time
between the LITTLE and big cores to conserve energy while still
meeting the performance requirements.

\figref{fig:BODYTRACK_timeline} shows the results of this experiment.
The vertical dashed line---at frame 99---represents when the second
application begins.  The figure clearly shows adaptive control's
benefits in this dynamic scenario.  When the second application
starts, the controller detects \texttt{bodytrack}'s performance
dip--rather than detecting the new application specifically---and it
changes resource allocation (increasing clockspeed and moving
bodytrack from 4 to 3 big cores).  The learning system however, does
not have any inherent mechanism to measure the change or adapt to the
altered performance.  While we could theoretically add feedback to the
learner and re-estimate the configuration space whenever the
environment changes, doing so is impractical due to high overhead for
learners capable of handling this complexity
\cite{Paragon,quasar,LEO}.


\subsection{Challenges of Parameter-free Control}
The adaptive controller requires user-specified parameters and
\figref{fig:STREAM_timeline} shows the consequences of getting those
parameters wrong. The controller's \emph{pole} is a particularly
important parameter.  Control engineers tune the pole with a model to
trade response time for noise sensitivity.  This model may be an
abstraction but is considered \emph{ground truth}
\cite{Hellerstein2004a}, meaning all possible resource configurations
the controller might select have been directly measured for some
input.  \SYSTEM{}, however, tunes the pole based on an estimated
model, which may have noise and/or errors.



\begin{wrapfigure}{r}{0.5\columnwidth} 
%\begin{figure}
%\centering
\input{img/BODYTRACK-example2-resized.tex}
\caption{Comparison of carefully tuned and default poles.}
\label{fig:not-simple}
%\end{figure}
\end{wrapfigure}
To demonstrate the pole's importance when using a learned model, we
again control \texttt{bodytrack}, this time using the adaptive
controller from the previous subsection with a model produced by the
learner from the first subsection.  We compare the results with a
carefully tuned pole to those using the default pole provided by the
controller developers \cite{POET}.

\figref{fig:not-simple} shows the results.  The carefully tuned pole
converges because the pole accounts for the learned model's error. The
default pole, however, oscillates around the performance target,
resulting in a number of missed deadlines.  Additionally, the frames
that exceed the desired performance waste energy because they spend
more time on the big, inefficient cores. The pole parameterizes the
system's \emph{inertia}---dictating how fast it should react to
environmental changes.  If the estimated model is noisy, the
controller should trust it less and move slowly. Rather than require
users with both computing and control knowledge to tune the pole,
\emph{\SYSTEM{} incorporates the learner's confidence interval and
  estimated variance to compute a pole that provides probabilistic
  convergence guarantees.}


